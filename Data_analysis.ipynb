{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab86d783",
   "metadata": {},
   "source": [
    "### Data analysis workflow\n",
    "Normalization -> Highly variable genes (HVGs) -> Differential expression genes (DEG) analysis -> Merge files into a total file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422806da",
   "metadata": {},
   "source": [
    "### Normalization and HVGs\n",
    "Norm_hvg.py\n",
    "\n",
    "* Unable to run because no file here, only for displaying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656fbab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "os.environ.setdefault(\"NUMBA_CACHE_DIR\", \"./numba_cache\")\n",
    "\n",
    "\n",
    "def resolve_file(candidates: List[str], base_dir: Path) -> Path:\n",
    "    \"\"\"Return the first existing path from candidates (absolute or relative to base_dir/..).\"\"\"\n",
    "    for name in candidates:\n",
    "        path = Path(name)\n",
    "        if path.is_file():\n",
    "            return path\n",
    "        for root in (base_dir, base_dir.parent):\n",
    "            maybe = root / name\n",
    "            if maybe.is_file():\n",
    "                return maybe\n",
    "    raise FileNotFoundError(f\"None of these files exist: {candidates}\")\n",
    "\n",
    "\n",
    "def load_metadata(meta_candidates: List[str], base_dir: Path) -> pd.DataFrame:\n",
    "    meta_path = resolve_file(meta_candidates, base_dir)\n",
    "    with open(meta_path, \"rb\") as fh:\n",
    "        header = fh.read(4)\n",
    "\n",
    "    try:\n",
    "        if header.startswith(b\"PK\") or meta_path.suffix.lower() in {\".xls\", \".xlsx\"}:\n",
    "            meta = pd.read_excel(meta_path)\n",
    "        else:\n",
    "            meta = pd.read_csv(\n",
    "                meta_path,\n",
    "                encoding=\"utf-8\",\n",
    "                encoding_errors=\"replace\",\n",
    "                engine=\"python\",\n",
    "                on_bad_lines=\"skip\",\n",
    "            )\n",
    "    except Exception:\n",
    "        meta = pd.read_excel(meta_path)\n",
    "\n",
    "    if \"Barcode\" not in meta.columns:\n",
    "        raise KeyError(f\"{meta_path} is missing required column 'Barcode'\")\n",
    "    meta = meta.set_index(\"Barcode\")\n",
    "    return meta\n",
    "\n",
    "\n",
    "def stratified_sample(meta: pd.DataFrame, celltype_col: str, target_total: int, seed: int) -> Tuple[List[str], Dict[str, int], Dict[str, int]]:\n",
    "    \"\"\"Sample cells per cell type to approach target_total.\"\"\"\n",
    "    counts = meta[celltype_col].value_counts()\n",
    "    available = counts.to_dict()\n",
    "    total = counts.sum()\n",
    "\n",
    "    if total <= target_total:\n",
    "        selected = meta.index.to_list()\n",
    "        sampled = {ct: counts[ct] for ct in counts.index}\n",
    "        return selected, available, sampled\n",
    "\n",
    "    fractions = counts / total\n",
    "    ideal = fractions * target_total\n",
    "    sample_sizes = ideal.apply(np.floor).astype(int)\n",
    "    remainder = target_total - sample_sizes.sum()\n",
    "\n",
    "    fractional_part = (ideal - sample_sizes).sort_values(ascending=False)\n",
    "    for ct in fractional_part.index:\n",
    "        if remainder <= 0:\n",
    "            break\n",
    "        room = counts[ct] - sample_sizes[ct]\n",
    "        add = min(room, remainder)\n",
    "        sample_sizes[ct] += add\n",
    "        remainder -= add\n",
    "\n",
    "    if remainder > 0:\n",
    "        for ct in counts.index:\n",
    "            if remainder == 0:\n",
    "                break\n",
    "            room = counts[ct] - sample_sizes[ct]\n",
    "            if room <= 0:\n",
    "                continue\n",
    "            add = min(room, remainder)\n",
    "            sample_sizes[ct] += add\n",
    "            remainder -= add\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    selected: List[str] = []\n",
    "    for ct, n in sample_sizes.items():\n",
    "        pool = meta[meta[celltype_col] == ct].index.to_numpy()\n",
    "        if n <= 0:\n",
    "            continue\n",
    "        if n > len(pool):\n",
    "            n = len(pool)\n",
    "        chosen = rng.choice(pool, size=n, replace=False)\n",
    "        selected.extend(chosen.tolist())\n",
    "\n",
    "    sampled = sample_sizes.to_dict()\n",
    "    return selected, available, sampled\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Subsample cells (~10k) by cell type, normalize, and compute HVGs.\")\n",
    "    parser.add_argument(\"--target_total\", type=int, default=10000, help=\"Approximate total cells after sampling (default: 10000)\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Random seed for reproducible sampling\")\n",
    "    parser.add_argument(\"--celltype_col\", type=str, default=\"Cell_type\", help=\"Column in metadata that stores cell type labels\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    base_dir = Path(__file__).resolve().parent\n",
    "    h5_path = resolve_file([\"GSE174367_snRNA-seq_filtered_feature_bc_matrix.h5\"], base_dir)\n",
    "    meta = load_metadata([\"GSE174367_snRNA-seq_cell_meta.csv\", \"PFC_metadata_whole.csv\"], base_dir)\n",
    "\n",
    "    if args.celltype_col not in meta.columns:\n",
    "        raise KeyError(f\"Metadata missing column '{args.celltype_col}'. Available columns: {list(meta.columns)}\")\n",
    "    meta = meta[meta[args.celltype_col].notna()].copy()\n",
    "\n",
    "    raw_adata = sc.read_10x_h5(h5_path)\n",
    "    raw_adata.var_names_make_unique()\n",
    "    raw_adata = raw_adata[raw_adata.obs_names.isin(meta.index)].copy()\n",
    "    meta_aligned = meta.loc[raw_adata.obs_names]\n",
    "    raw_adata.obs = raw_adata.obs.join(meta_aligned, how=\"left\")\n",
    "\n",
    "    selected, available_counts, sampled_counts = stratified_sample(\n",
    "        raw_adata.obs, args.celltype_col, args.target_total, args.seed\n",
    "    )\n",
    "    adata = raw_adata[selected, :].copy()\n",
    "\n",
    "    before_sum = sum(available_counts.values())\n",
    "    after_sum = len(selected)\n",
    "    print(f\"Sampling {after_sum}/{before_sum} cells (~{args.target_total} target).\")\n",
    "\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    batch_key = \"Batch\" if \"Batch\" in adata.obs.columns else None\n",
    "    sc.pp.highly_variable_genes(\n",
    "        adata,\n",
    "        n_top_genes=2000,\n",
    "        flavor=\"seurat_v3\",\n",
    "        batch_key=batch_key,\n",
    "    )\n",
    "\n",
    "    hvg_df_raw = adata.var[adata.var[\"highly_variable\"]].copy()\n",
    "    hvg_df = hvg_df_raw.assign(\n",
    "        gene_name=hvg_df_raw.index,\n",
    "        mean=hvg_df_raw[\"means\"],\n",
    "        variance=hvg_df_raw[\"variances\"],\n",
    "        variance_norm=hvg_df_raw[\"variances_norm\"],\n",
    "        dispersion=hvg_df_raw[\"variances_norm\"],\n",
    "    )[[\"gene_name\", \"mean\", \"variance\", \"variance_norm\", \"dispersion\"]]\n",
    "\n",
    "    out_raw = base_dir / \"sampled_raw_counts.h5ad\"\n",
    "    out_norm = base_dir / \"sampled_normalized_expression.h5ad\"\n",
    "    out_hvg = base_dir / \"sampled_norm_hvg.h5ad\"\n",
    "    out_hvg_csv = base_dir / \"sampled_HVG.csv\"\n",
    "    out_counts = base_dir / \"sampled_celltype_counts.csv\"\n",
    "    out_meta = base_dir / \"GSE174367_snRNA-seq_cell_meta_sampled.csv\"\n",
    "\n",
    "    raw_subset = raw_adata[selected, :].copy()\n",
    "    raw_subset.write(out_raw, compression=\"gzip\")\n",
    "    adata.write(out_norm, compression=\"gzip\")\n",
    "    adata[:, adata.var[\"highly_variable\"]].write(out_hvg, compression=\"gzip\")\n",
    "    hvg_df.to_csv(out_hvg_csv, index=False)\n",
    "\n",
    "    # Save sampled metadata with Barcode column preserved\n",
    "    meta_sampled = adata.obs.copy()\n",
    "    meta_sampled.insert(0, \"Barcode\", meta_sampled.index)\n",
    "    meta_sampled.to_csv(out_meta, index=False)\n",
    "\n",
    "    counts_df = pd.DataFrame(\n",
    "        {\n",
    "            \"cell_type\": list(available_counts.keys()),\n",
    "            \"available\": list(available_counts.values()),\n",
    "            \"sampled\": [sampled_counts.get(ct, 0) for ct in available_counts.keys()],\n",
    "        }\n",
    "    )\n",
    "    counts_df.to_csv(out_counts, index=False)\n",
    "\n",
    "    print(f\"HVGs found: {hvg_df.shape[0]}\")\n",
    "    print(f\"Saved: {out_raw.name}, {out_norm.name}, {out_hvg.name}, {out_hvg_csv.name}, {out_counts.name}, {out_meta.name}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f41b1",
   "metadata": {},
   "source": [
    "### DEGs and merge files into total file\n",
    "Deg_and_merge.py\n",
    "\n",
    "* Unable to run because no file, only for displaying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc64574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "os.environ.setdefault(\"NUMBA_CACHE_DIR\", \"./numba_cache\")\n",
    "\n",
    "\n",
    "def resolve_file(candidates: List[str], base_dir: Path) -> Path:\n",
    "    for name in candidates:\n",
    "        path = Path(name)\n",
    "        if path.is_file():\n",
    "            return path\n",
    "        for root in (base_dir, base_dir.parent):\n",
    "            maybe = root / name\n",
    "            if maybe.is_file():\n",
    "                return maybe\n",
    "    raise FileNotFoundError(f\"None of these files exist: {candidates}\")\n",
    "\n",
    "\n",
    "def load_gene_list(base_dir: Path) -> List[str]:\n",
    "    gene_path = resolve_file([\"master_dictionary_gene_unique.csv\"], base_dir)\n",
    "    gene_dict = pd.read_csv(\n",
    "        gene_path,\n",
    "        encoding=\"utf-8\",\n",
    "        encoding_errors=\"replace\",\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\",\n",
    "    )\n",
    "    gene_list = (\n",
    "        gene_dict[\"gene_symbol\"]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "    return gene_list\n",
    "\n",
    "\n",
    "def choose_reference_and_target(diag_values: List[str]) -> Tuple[str, str]:\n",
    "    diag_set = set(diag_values)\n",
    "    if not diag_set:\n",
    "        raise ValueError(\"Diagnosis column is empty after filtering.\")\n",
    "\n",
    "    if \"Control\" in diag_set:\n",
    "        ref = \"Control\"\n",
    "    elif \"CT\" in diag_set:\n",
    "        ref = \"CT\"\n",
    "    else:\n",
    "        ref = sorted(diag_set)[0]\n",
    "\n",
    "    non_ref = [g for g in diag_values if g != ref]\n",
    "    if not non_ref:\n",
    "        raise ValueError(f\"Only one diagnosis group ({ref}) present; cannot run DEG.\")\n",
    "\n",
    "    target = \"AD\" if \"AD\" in non_ref else non_ref[0]\n",
    "    return ref, target\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"DEG on sampled dataset + merged outputs.\")\n",
    "    parser.add_argument(\"--adata\", type=str, default=\"sampled_normalized_expression.h5ad\", help=\"Input AnnData file\")\n",
    "    parser.add_argument(\"--celltype_col\", type=str, default=\"Cell_type\", help=\"Cell type column in obs\")\n",
    "    parser.add_argument(\"--diagnosis_col\", type=str, default=\"Diagnosis\", help=\"Diagnosis column in obs\")\n",
    "    parser.add_argument(\"--min_cells\", type=int, default=20, help=\"Minimum cells per cell type to run DEG\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    base_dir = Path(__file__).resolve().parent\n",
    "    adata_path = resolve_file([args.adata, \"normalized_expression.h5ad\"], base_dir)\n",
    "\n",
    "    adata = sc.read(adata_path)\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "    if args.celltype_col not in adata.obs.columns and \"Cell.Type\" in adata.obs.columns:\n",
    "        args.celltype_col = \"Cell.Type\"\n",
    "\n",
    "    if args.celltype_col not in adata.obs.columns:\n",
    "        raise KeyError(f\"Missing cell type column: {args.celltype_col}\")\n",
    "    if args.diagnosis_col not in adata.obs.columns:\n",
    "        raise KeyError(f\"Missing diagnosis column: {args.diagnosis_col}\")\n",
    "\n",
    "    gene_list = load_gene_list(base_dir)\n",
    "    genes_in_data = [g for g in gene_list if g in adata.var_names]\n",
    "    if not genes_in_data:\n",
    "        raise ValueError(\"No genes from master_dictionary_gene_unique.csv found in expression matrix.\")\n",
    "    adata = adata[:, genes_in_data].copy()\n",
    "    print(f\"Using {len(genes_in_data)} genes from master_dictionary_gene_unique.csv\")\n",
    "\n",
    "    cell_types = sorted(adata.obs[args.celltype_col].dropna().unique())\n",
    "    out_dir = base_dir\n",
    "    logfc_dict: Dict[str, pd.Series] = {}\n",
    "    deg_files: List[Tuple[str, Path]] = []\n",
    "\n",
    "    for ct in cell_types:\n",
    "        ad_ct = adata[adata.obs[args.celltype_col] == ct].copy()\n",
    "        if ad_ct.n_obs < args.min_cells:\n",
    "            print(f\"Skip {ct}: too few cells ({ad_ct.n_obs})\")\n",
    "            continue\n",
    "\n",
    "        diag_values = ad_ct.obs[args.diagnosis_col].dropna().unique().tolist()\n",
    "        if len(diag_values) < 2:\n",
    "            print(f\"Skip {ct}: only one diagnosis group ({diag_values})\")\n",
    "            continue\n",
    "\n",
    "        ref, target = choose_reference_and_target(diag_values)\n",
    "        sc.tl.rank_genes_groups(\n",
    "            ad_ct,\n",
    "            groupby=args.diagnosis_col,\n",
    "            reference=ref,\n",
    "            method=\"wilcoxon\",\n",
    "        )\n",
    "        sc.tl.filter_rank_genes_groups(\n",
    "            ad_ct,\n",
    "            min_in_group_fraction=0.1,\n",
    "            max_out_group_fraction=0.1,\n",
    "            min_fold_change=1.5,\n",
    "        )\n",
    "\n",
    "        deg_df = sc.get.rank_genes_groups_df(ad_ct, group=None)\n",
    "        safe_ct = re.sub(r\"[^0-9A-Za-z._-]+\", \"_\", ct)\n",
    "        out_path = out_dir / f\"Sampled_DEG_{safe_ct}.csv\"\n",
    "        deg_df.to_csv(out_path, index=False)\n",
    "        deg_files.append((ct, out_path))\n",
    "\n",
    "        deg_target = deg_df[deg_df[\"group\"] == target] if \"group\" in deg_df.columns else deg_df\n",
    "        logfc_dict[ct] = deg_target.set_index(\"names\")[\"logfoldchanges\"]\n",
    "        print(f\"{ct}: {ad_ct.n_obs} cells, DEG -> {out_path.name}\")\n",
    "\n",
    "    if not deg_files:\n",
    "        raise RuntimeError(\"No DEG files were generated. Check filters and metadata.\")\n",
    "\n",
    "    logfc_df = pd.DataFrame(logfc_dict)\n",
    "    logfc_df.insert(0, \"Gene\", logfc_df.index)\n",
    "    out_logfc = out_dir / \"Sampled_DEG_Log_CellType.csv\"\n",
    "    logfc_df.to_csv(out_logfc, index=False)\n",
    "\n",
    "    merged_list = []\n",
    "    drop_cols = {\"Gene\", \"ASC\", \"EX\", \"INH\", \"MG\", \"ODC\", \"CellType\", \"OPC\", \"PER.END\", \"cell_type\"}\n",
    "    for ct, fp in deg_files:\n",
    "        df = pd.read_csv(fp)\n",
    "        df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "        df.insert(0, \"cell_type\", ct)\n",
    "        if df.shape[1] > 7:\n",
    "            df = df.iloc[:, :7]\n",
    "        merged_list.append(df)\n",
    "\n",
    "    merged_df = pd.concat(merged_list, ignore_index=True)\n",
    "    out_merged = out_dir / \"Sampled_DEG_celltype_merged.csv\"\n",
    "    merged_df.to_csv(out_merged, index=False)\n",
    "\n",
    "    print(f\"LogFC matrix: {out_logfc.name}\")\n",
    "    print(f\"Merged DEG: {out_merged.name} (from {len(merged_list)} cell types)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
